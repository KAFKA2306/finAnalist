{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simulation_content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 393\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;66;03m# simulation.pyファイルの作成\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     simulation_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124mimport pandas as pd\u001b[39m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124mimport numpy as np\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124m                    \u001b[39m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 393\u001b[0m create_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulation.py\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43msimulation_content\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'simulation_content' is not defined"
     ]
    }
   ],
   "source": [
    "def create_file(file_name, content):\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(content)\n",
    "\n",
    "def create_necessary_files():\n",
    "    # config.iniファイルの作成\n",
    "    config_content = \"\"\"\n",
    "[API_KEYS]\n",
    "google_news_api = your_google_news_api_key\n",
    "news_api = your_news_api_key\n",
    "quick_fs_api = your_quick_fs_api_key\n",
    "speeda_api = your_speeda_api_key\n",
    "bloomberg_api = your_bloomberg_api_key\n",
    "claude_api = your_claude_api_key\n",
    "\n",
    "[SLACK]\n",
    "slack_token = your_slack_token\n",
    "\"\"\"\n",
    "    create_file(\"config.ini\", config_content)\n",
    "\n",
    "    # data_collection.pyファイルの作成\n",
    "    data_collection_content = \"\"\"\n",
    "import configparser\n",
    "import requests\n",
    "\n",
    "class DataCollector:\n",
    "    def __init__(self):\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read('config.ini')\n",
    "        self.api_keys = config['API_KEYS']\n",
    "\n",
    "    def collect_news_data(self, theme):\n",
    "        # Google News APIを使用してニュース記事を収集\n",
    "        google_news_api_key = self.api_keys['google_news_api']\n",
    "        url = f\"https://newsapi.org/v2/everything?q={theme}&apiKey={google_news_api_key}\"\n",
    "        response = requests.get(url)\n",
    "        news_data = response.json()\n",
    "        return news_data['articles']\n",
    "\n",
    "    def collect_company_data(self, company_names):\n",
    "        # QuickFSを使用して企業情報を収集\n",
    "        quick_fs_api_key = self.api_keys['quick_fs_api']\n",
    "        company_data = {}\n",
    "        for name in company_names:\n",
    "            url = f\"https://quickfs.net/api/v1/data/company/{name}?api_key={quick_fs_api_key}\"\n",
    "            response = requests.get(url)\n",
    "            company_data[name] = response.json()\n",
    "        return company_data\n",
    "\n",
    "    def collect_financial_data(self, company_names):\n",
    "        # Bloomberg APIを使用して財務データを収集\n",
    "        bloomberg_api_key = self.api_keys['bloomberg_api']\n",
    "        financial_data = {}\n",
    "        for name in company_names:\n",
    "            url = f\"https://www.bloomberg.com/markets/api/bulk-time-series/price/{name}:JP?timeFrame=5_YEAR&period=daily&volumePeriod=daily&currency=JPY&apiKey={bloomberg_api_key}\"\n",
    "            response = requests.get(url)\n",
    "            financial_data[name] = response.json()\n",
    "        return financial_data\n",
    "\"\"\"\n",
    "    create_file(\"data_collection.py\", data_collection_content)\n",
    "\n",
    "    # news_analysis.pyファイルの作成\n",
    "    news_analysis_content = \"\"\"\n",
    "from transformers import pipeline\n",
    "\n",
    "class NewsAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "        \n",
    "    def extract_companies(self, news_articles):\n",
    "        company_names = set()\n",
    "        for article in news_articles:\n",
    "            result = self.ner_pipeline(article['title'] + ' ' + article['description'])\n",
    "            for entity in result:\n",
    "                if entity['entity'] == 'B-ORG':\n",
    "                    company_names.add(entity['word'])\n",
    "        return list(company_names)\n",
    "\n",
    "    def analyze_news_content(self, news_articles):\n",
    "        # Claude APIを使用してニュース記事の内容を分析\n",
    "        claude_api_key = self.api_keys['claude_api']\n",
    "        analysis_results = []\n",
    "        for article in news_articles:\n",
    "            url = \"https://api.anthropic.com/v1/complete\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"X-API-Key\": claude_api_key\n",
    "            }\n",
    "            data = {\n",
    "                \"prompt\": f\"Please analyze the following news article:\\\\n\\\\n{article['title']}\\\\n{article['description']}\\\\n\\\\nProvide a summary of the key points and sentiment analysis.\",\n",
    "                \"model\": \"claude-v1\",\n",
    "                \"max_tokens_to_sample\": 100\n",
    "            }\n",
    "            response = requests.post(url, headers=headers, json=data)\n",
    "            analysis_results.append(response.json()['completion'])\n",
    "        return analysis_results\n",
    "\n",
    "    def save_news_analysis_results(self, results):\n",
    "        with open(\"news_analysis_results.txt\", \"w\") as file:\n",
    "            for result in results:\n",
    "                file.write(result + \"\\\\n\\\\n\")\n",
    "\"\"\"\n",
    "    create_file(\"news_analysis.py\", news_analysis_content)\n",
    "\n",
    "    # company_analysis.pyファイルの作成\n",
    "    company_analysis_content = \"\"\"\n",
    "class CompanyAnalyzer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def analyze_company_info(self, company_data):\n",
    "        # Claude APIを使用して企業情報から定性情報を抽出・要約\n",
    "        claude_api_key = self.api_keys['claude_api']\n",
    "        analysis_results = {}\n",
    "        for name, data in company_data.items():\n",
    "            url = \"https://api.anthropic.com/v1/complete\"\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"X-API-Key\": claude_api_key\n",
    "            }\n",
    "            prompt = f\"Please analyze the following company information:\\\\n\\\\n{data}\\\\n\\\\nProvide a summary of the key points and extract relevant qualitative information.\"\n",
    "            request_data = {\n",
    "                \"prompt\": prompt,\n",
    "                \"model\": \"claude-v1\",\n",
    "                \"max_tokens_to_sample\": 150\n",
    "            }\n",
    "            response = requests.post(url, headers=headers, json=request_data)\n",
    "            analysis_results[name] = response.json()['completion']\n",
    "        return analysis_results\n",
    "\n",
    "    def analyze_financial_statements(self, financial_data):\n",
    "        # 財務諸表データに基づいて売上高、利益、成長率等を分析\n",
    "        analysis_results = {}\n",
    "        for name, data in financial_data.items():\n",
    "            revenue = [d['revenue'] for d in data if 'revenue' in d]\n",
    "            profit = [d['profit'] for d in data if 'profit' in d]\n",
    "            growth_rate = (revenue[-1] - revenue[0]) / revenue[0] if len(revenue) > 1 else None\n",
    "            analysis_results[name] = {\n",
    "                'revenue': revenue,\n",
    "                'profit': profit,\n",
    "                'growth_rate': growth_rate\n",
    "            }\n",
    "        return analysis_results\n",
    "\n",
    "    def save_company_analysis_results(self, results):\n",
    "        with open(\"company_analysis_results.txt\", \"w\") as file:\n",
    "            for name, result in results.items():\n",
    "                file.write(f\"Company: {name}\\\\n\")\n",
    "                file.write(result + \"\\\\n\\\\n\")\n",
    "\"\"\"\n",
    "    create_file(\"company_analysis.py\", company_analysis_content)\n",
    "\n",
    "    # financial_analysis.pyファイルの作成\n",
    "    financial_analysis_content = \"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "class FinancialAnalyzer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def calculate_valuation_metrics(self, financial_data):\n",
    "        valuation_metrics = {}\n",
    "        for name, data in financial_data.items():\n",
    "            revenue = [d['revenue'] for d in data if 'revenue' in d]\n",
    "            profit = [d['profit'] for d in data if 'profit' in d]\n",
    "            market_cap = [d['market_cap'] for d in data if 'market_cap' in d]\n",
    "            if revenue and profit and market_cap:\n",
    "                pe_ratio = market_cap[-1] / profit[-1]\n",
    "                ps_ratio = market_cap[-1] / revenue[-1]\n",
    "                valuation_metrics[name] = {\n",
    "                    'pe_ratio': pe_ratio,\n",
    "                    'ps_ratio': ps_ratio\n",
    "                }\n",
    "        return valuation_metrics\n",
    "    \n",
    "    def compare_with_industry_average(self, valuation_metrics):\n",
    "        # 業種平均との比較分析\n",
    "        industry_averages = {\n",
    "            'pe_ratio': 20,\n",
    "            'ps_ratio': 2\n",
    "        }\n",
    "        comparison_results = {}\n",
    "        for name, metrics in valuation_metrics.items():\n",
    "            pe_ratio_diff = (metrics['pe_ratio'] - industry_averages['pe_ratio']) / industry_averages['pe_ratio']\n",
    "            ps_ratio_diff = (metrics['ps_ratio'] - industry_averages['ps_ratio']) / industry_averages['ps_ratio']\n",
    "            comparison_results[name] = {\n",
    "                'pe_ratio_diff': pe_ratio_diff,\n",
    "                'ps_ratio_diff': ps_ratio_diff\n",
    "            }\n",
    "        return comparison_results\n",
    "\n",
    "    def perform_dcf_valuation(self, financial_data, growth_forecast):\n",
    "        dcf_valuation_results = {}\n",
    "        for name, data in financial_data.items():\n",
    "            # 将来のキャッシュフロー予測\n",
    "            cash_flows = [d['free_cash_flow'] for d in data if 'free_cash_flow' in d]\n",
    "            forecast_period = 5\n",
    "            forecast_cash_flows = [cash_flows[-1] * (1 + growth_forecast) ** i for i in range(1, forecast_period + 1)]\n",
    "            \n",
    "            # 割引率の設定\n",
    "            discount_rate = 0.08\n",
    "            \n",
    "            # 割引現在価値の計算\n",
    "            discount_factors = [(1 + discount_rate) ** i for i in range(1, forecast_period + 1)]\n",
    "            discounted_cash_flows = [cf / df for cf, df in zip(forecast_cash_flows, discount_factors)]\n",
    "            \n",
    "            # 企業価値の計算\n",
    "            terminal_value = discounted_cash_flows[-1] * (1 + growth_forecast) / (discount_rate - growth_forecast)\n",
    "            enterprise_value = sum(discounted_cash_flows) + terminal_value\n",
    "            \n",
    "            # 株主価値の計算\n",
    "            net_debt = data[-1]['total_debt'] - data[-1]['cash_and_equivalents']\n",
    "            equity_value = enterprise_value - net_debt\n",
    "            dcf_valuation_results[name] = equity_value\n",
    "        \n",
    "        return dcf_valuation_results\n",
    "    \n",
    "    def detect_anomalies(self, financial_data):\n",
    "        # 財務データの異常値検知\n",
    "        anomalies = {}\n",
    "        for name, data in financial_data.items():\n",
    "            df = pd.DataFrame(data)\n",
    "            clf = IsolationForest(contamination=0.1)\n",
    "            clf.fit(df)\n",
    "            anomaly_scores = clf.decision_function(df)\n",
    "            anomalies[name] = list(df[anomaly_scores < 0].index)\n",
    "        \n",
    "        return anomalies\n",
    "\n",
    "    def save_financial_analysis_results(self, results):\n",
    "        with open(\"financial_analysis_results.txt\", \"w\") as file:\n",
    "            for name, result in results.items():\n",
    "                file.write(f\"Company: {name}\\\\n\")\n",
    "                file.write(str(result) + \"\\\\n\\\\n\")\n",
    "\"\"\"\n",
    "    create_file(\"financial_analysis.py\", financial_analysis_content)\n",
    "\n",
    "    # report_generation.pyファイルの作成\n",
    "    report_generation_content = \"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "class ReportGenerator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def generate_markdown_report(self, analysis_results):\n",
    "        report = \"# Investment Theme Analysis Report\\\\n\\\\n\"\n",
    "        \n",
    "        # ニュース分析結果\n",
    "        report += \"## News Analysis\\\\n\\\\n\"\n",
    "        for i, result in enumerate(analysis_results['news_analysis'], start=1):\n",
    "            report += f\"### Article {i}\\\\n\\\\n\"\n",
    "            report += result + \"\\\\n\\\\n\"\n",
    "        \n",
    "        # 企業分析結果\n",
    "        report += \"## Company Analysis\\\\n\\\\n\"\n",
    "        for name, result in analysis_results['company_analysis'].items():\n",
    "            report += f\"### {name}\\\\n\\\\n\"\n",
    "            report += result + \"\\\\n\\\\n\"\n",
    "        \n",
    "        # 財務分析結果\n",
    "        report += \"## Financial Analysis\\\\n\\\\n\"\n",
    "        for name, result in analysis_results['financial_analysis'].items():\n",
    "            report += f\"### {name}\\\\n\\\\n\"\n",
    "            report += f\"- Valuation Metrics: {result['valuation_metrics']}\\\\n\"\n",
    "            report += f\"- Industry Comparison: {result['industry_comparison']}\\\\n\"\n",
    "            report += f\"- DCF Valuation: {result['dcf_valuation']}\\\\n\"\n",
    "            report += f\"- Anomalies: {result['anomalies']}\\\\n\\\\n\"\n",
    "        \n",
    "        # 投資判断の提示\n",
    "        report += \"## Investment Suggestions\\\\n\\\\n\"\n",
    "        for suggestion in analysis_results['investment_suggestions']:\n",
    "            report += f\"- {suggestion}\\\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "    def generate_visualizations(self, analysis_results):\n",
    "        visualizations = []\n",
    "        \n",
    "        # 企業の財務指標の推移\n",
    "        for name, result in analysis_results['financial_analysis'].items():\n",
    "            revenue = result['revenue']\n",
    "            profit = result['profit']\n",
    "            fig = px.line(x=list(range(len(revenue))), y=[revenue, profit], labels={'x': 'Year', 'y': 'Amount'},\n",
    "                        title=f\"{name} - Revenue and Profit\")\n",
    "            fig.update_layout(legend_title_text='Metric')\n",
    "            fig.update_traces(textposition=\"bottom right\")\n",
    "            visualizations.append(fig)\n",
    "        \n",
    "        return visualizations\n",
    "\n",
    "    def generate_interactive_report(self, markdown_report, visualizations):\n",
    "        # Plotlyを使用してインタラクティブなレポートを生成\n",
    "        report = markdown_report\n",
    "        for fig in visualizations:\n",
    "            report += f\"\\\\n\\\\n{fig.to_html(full_html=False)}\\\\n\\\\n\"\n",
    "        \n",
    "        with open(\"investment_theme_report.html\", \"w\") as file:\n",
    "            file.write(report)\n",
    "\n",
    "    def provide_investment_suggestions(self, analysis_results):\n",
    "        suggestions = []\n",
    "        \n",
    "        # ニュース分析に基づく提案\n",
    "        positive_news = [result for result in analysis_results['news_analysis'] if \"positive\" in result.lower()]\n",
    "        if len(positive_news) > 0:\n",
    "            suggestions.append(\"Consider investing in companies with positive news sentiment.\")\n",
    "        \n",
    "        # 企業分析に基づく提案\n",
    "        for name, result in analysis_results['company_analysis'].items():\n",
    "            if \"strong financial performance\" in result.lower():\n",
    "                suggestions.append(f\"Consider investing in {name} due to its strong financial performance.\")\n",
    "        \n",
    "        # バリュエーション分析に基づく提案\n",
    "        for name, result in analysis_results['financial_analysis'].items():\n",
    "            if result['valuation_metrics']['pe_ratio'] < 15 and result['valuation_metrics']['ps_ratio'] < 1.5:\n",
    "                suggestions.append(f\"{name} appears undervalued based on its P/E and P/S ratios.\")\n",
    "        \n",
    "        return suggestions\n",
    "\"\"\"\n",
    "        create_file(\"report_generation.py\", report_generation_content)\n",
    "\n",
    "    # simulation.pyファイルの作成\n",
    "    simulation_content = \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "\n",
    "class InvestmentSimulator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_historical_price_data(self, company_names, start_date, end_date):\n",
    "        historical_data = {}\n",
    "        for name in company_names:\n",
    "            ticker = yf.Ticker(name)\n",
    "            data = ticker.history(start=start_date, end=end_date)\n",
    "            historical_data[name] = data['Close']\n",
    "        return historical_data\n",
    "\n",
    "    def backtest_investment_strategies(self, historical_data, strategies):\n",
    "        backtest_results = {}\n",
    "        for strategy in strategies:\n",
    "            portfolio_values = []\n",
    "            for name, data in historical_data.items():\n",
    "                if strategy == 'equal_weight':\n",
    "                    num_shares = 1000 // data.iloc[0]\n",
    "                    portfolio_value = num_shares * data\n",
    "                elif strategy == 'momentum':\n",
    "                    returns = data.pct_change()\n",
    "                    signal = np.where(returns.rolling(window=50).mean() > returns.rolling(window=200).mean(), 1, 0)\n",
    "                    num_shares = 1000 // data.iloc[0]\n",
    "                    portfolio_value = num_shares * data * signal\n",
    "                elif strategy == 'mean_reversion':\n",
    "                    returns = data.pct_change()\n",
    "                    signal = np.where(returns.rolling(window=50).mean() < returns.rolling(window=200).mean(), 1, 0)\n",
    "                    num_shares = 1000 // data.iloc[0]\n",
    "                    portfolio_value = num_shares * data * signal\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "                portfolio_values.append(portfolio_value)\n",
    "\n",
    "            backtest_results[strategy] = pd.concat(portfolio_values, axis=1).sum(axis=1)\n",
    "\n",
    "        return backtest_results\n",
    "\n",
    "    def evaluate_risk_return(self, backtest_results):\n",
    "        risk_return_metrics = {}\n",
    "        for strategy, returns in backtest_results.items():\n",
    "            total_return = (returns.iloc[-1] - returns.iloc[0]) / returns.iloc[0]\n",
    "            annual_return = (1 + total_return) ** (252 / len(returns)) - 1\n",
    "            annual_volatility = returns.pct_change().std() * np.sqrt(252)\n",
    "            sharpe_ratio = annual_return / annual_volatility\n",
    "\n",
    "            risk_return_metrics[strategy] = {\n",
    "                'Total Return': total_return,\n",
    "                'Annual Return': annual_return,\n",
    "                'Annual Volatility': annual_volatility,\n",
    "                'Sharpe Ratio': sharpe_ratio\n",
    "            }\n",
    "\n",
    "        return risk_return_metrics\n",
    "\n",
    "    def propose_optimal_strategy(self, risk_return_metrics):\n",
    "        optimal_strategy = max(risk_return_metrics, key=lambda x: risk_return_metrics[x]['Sharpe Ratio'])\n",
    "        return optimal_strategy\n",
    "                    \n",
    "\"\"\"\n",
    "\n",
    "create_file(\"simulation.py\", simulation_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "上記のコードでは、各ファイルにおいて、コメントで示されていた部分を実際のコードで補完しました。\n",
    "\n",
    "- `data_collection.py`: Google News API、QuickFS API、Bloomberg APIを使用してデータを収集するコードを追加しました。\n",
    "- `news_analysis.py`: 自然言語処理ライブラリ（Transformers）を使用してニュース記事から企業名を抽出し、Claude APIを使用してニュース記事の内容を分析するコードを追加しました。\n",
    "- `company_analysis.py`: Claude APIを使用して企業情報から定性情報を抽出・要約し、財務諸表データから売上高、利益、成長率を分析するコードを追加しました。\n",
    "- `financial_analysis.py`: バリュエーション指標（P/E ratio、P/S ratio）の計算、業種平均との比較分析、DCF法による企業価値評価、異常値検知のコードを追加しました。\n",
    "- `report_generation.py`: 分析結果をMarkdown形式でレポートにまとめ、Plotlyを使用してインタラクティブな可視化を生成するコードを追加しました。また、分析結果に基づいて投資判断の提案を行うコードも追加しました。\n",
    "- `simulation.py`: Yahoo Financeから過去の株価データを取得し、異なる投資戦略（等ウェイト、モメンタム、平均回帰）のバックテストを実施するコードを追加しました。また、リスク・リターン指標の評価と最適な戦略の提案を行うコードも追加しました。\n",
    "\n",
    "これらのコードにより、各モジュールの機能が実装され、投資テーマ分析ツールとして動作するようになります。ただし、APIキーやデータベースへの接続設定などは、実際の環境に合わせて適切に設定する必要があります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この部分をスクリプトの最後に移動する\n",
    "if __name__ == \"__main__\":\n",
    "    create_necessary_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
